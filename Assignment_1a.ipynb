{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Assignment No 1\n",
    "######*Sibt ul Hussain*\n",
    "----\n",
    "##Goal\n",
    "\n",
    "Your goal in this assigment is to implement and refresh the concepts learned during the previous two weeks using the Python language. This will not only solidify your Python understanding but also give you strong footing for further advancement :)\n",
    "\n",
    "**Note** Please note that you are not allowed to use any other library whatsoever, and all the tools required to complete the tasks have already been discussed in the Lab. In case you need any help you can post on Piazza.\n",
    "\n",
    "##Submission Instructions\n",
    "You are required to submit the original notebook file on the Slate (with .ipynb extension), with complete set of outputs. Students failing to do so will get zero marks. \n",
    "\n",
    "*Please read each step carefully and understand it fully before proceeding with code writing*\n",
    "\n",
    "##Plagiarism\n",
    "Any form of plagiarism will not be tolerated and result in 0 marks. No relaxation whatsoever, so avoid copying and start enjoying :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Hello IPython\n",
    "----------------\n",
    "The IPython notebook is an application to build interactive computational notebooks. You'll be using them to complete labs and homework. Once you've set up Python, please download this  ipython notebook and open it with IPython by typing\n",
    "\n",
    "ipython notebook --pylab=inline Assignment\\#1\n",
    "\n",
    "For the rest of the assignment, use your local copy of this page, running on IPython.\n",
    "\n",
    "Notebooks are composed of many \"cells\", which can contain text (like this one), or code (like the one below). Double click on the cell below, and evaluate it by clicking the \"play\" button above, or by hitting shift + enter.\n",
    "\n",
    "**So Lets Start**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IPython version:      4.0.1 (need at least 1.0)\n",
      "Numpy version:        1.10.1 (need at least 1.7.1)\n",
      "SciPy version:        0.16.0 (need at least 0.12.0)\n",
      "Pandas version:       0.17.1 (need at least 0.11.0)\n",
      "Mapltolib version:    1.5.0 (need at least 1.2.1)\n",
      "Scikit-Learn version: 0.17 (need at least 0.13.1)\n",
      "requests version:     2.8.1 (need at least 1.2.3)\n",
      "BeautifulSoup version:4.4.1 (need at least 4.0)\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-bcb2cf19663e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;31m#Seaborn is a nice library for visualizations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"Seaborn version:      {} (need at least 0.3.1)\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseaborn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "#NoteBook for Assignment on the Introduction to Data...\n",
    "#Written By: Sibt ul Hussain\n",
    "\n",
    "\n",
    "#IPython is what you are using now to run the notebook\n",
    "import IPython\n",
    "print (\"IPython version:      {} (need at least 1.0)\".format(IPython.__version__))\n",
    "\n",
    "# Numpy is a library for working with Arrays\n",
    "import numpy as np\n",
    "print (\"Numpy version:        {} (need at least 1.7.1)\".format(np.__version__))\n",
    "\n",
    "# SciPy implements many different numerical algorithms\n",
    "import scipy as sp\n",
    "print (\"SciPy version:        {} (need at least 0.12.0)\".format(sp.__version__))\n",
    "\n",
    "# Pandas makes working with data tables easier\n",
    "import pandas as pd\n",
    "print (\"Pandas version:       {} (need at least 0.11.0)\".format(pd.__version__))\n",
    "\n",
    "# Module for plotting\n",
    "import matplotlib\n",
    "print (\"Mapltolib version:    {} (need at least 1.2.1)\".format(matplotlib.__version__))\n",
    "\n",
    "# SciKit Learn implements several Machine Learning algorithms\n",
    "import sklearn\n",
    "print (\"Scikit-Learn version: {} (need at least 0.13.1)\".format(sklearn.__version__))\n",
    "\n",
    "# Requests is a library for getting data from the Web\n",
    "import requests\n",
    "print (\"requests version:     {} (need at least 1.2.3)\".format(requests.__version__))\n",
    "\n",
    "#BeautifulSoup is a library to parse HTML and XML documents\n",
    "import bs4\n",
    "print (\"BeautifulSoup version:{} (need at least 4.0)\".format(bs4.__version__))\n",
    "\n",
    "\n",
    "#Seaborn is a nice library for visualizations\n",
    "import seaborn\n",
    "print (\"Seaborn version:      {} (need at least 0.3.1)\".format(seaborn.__version__))\n",
    "\n",
    "#Pattern has lots of tools for working with data from the internet\n",
    "#import pattern\n",
    "#print (\"Pattern version:      {} (need at least 2.6)\".format(pattern.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "#Download the IRIS dataset\n",
    "#\"!\" means run the bash (shell) command, if you are unable to download the data, go \n",
    "# to given link and manually d\n",
    "!wget http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [],
   "source": [
    "#import pandas and name this namespace as pd\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "File b'iris' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-a976c078a470>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Load data and name the columns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'iris'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'SepalLength'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'SepalWidth'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'PetalLength'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'PetalWidth'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Class'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\zainali\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, dialect, compression, doublequote, escapechar, quotechar, quoting, skipinitialspace, lineterminator, header, index_col, names, prefix, skiprows, skipfooter, skip_footer, na_values, true_values, false_values, delimiter, converters, dtype, usecols, engine, delim_whitespace, as_recarray, na_filter, compact_ints, use_unsigned, low_memory, buffer_lines, warn_bad_lines, error_bad_lines, keep_default_na, thousands, comment, decimal, parse_dates, keep_date_col, dayfirst, date_parser, memory_map, float_precision, nrows, iterator, chunksize, verbose, encoding, squeeze, mangle_dupe_cols, tupleize_cols, infer_datetime_format, skip_blank_lines)\u001b[0m\n\u001b[0;32m    496\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    497\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 498\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    499\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    500\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\zainali\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 275\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    276\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mchunksize\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\zainali\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    588\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 590\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    591\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_options_with_defaults\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\zainali\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m    729\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 731\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    732\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    733\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\zainali\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1101\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'allow_leading_cols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1103\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_parser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1105\u001b[0m         \u001b[1;31m# XXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader.__cinit__ (pandas\\parser.c:3246)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._setup_parser_source (pandas\\parser.c:6111)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: File b'iris' does not exist"
     ]
    }
   ],
   "source": [
    "#Load data and name the columns\n",
    "data=pd.read_csv('iris')\n",
    "data.columns=['SepalLength','SepalWidth','PetalLength','PetalWidth','Class']\n",
    "print (data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [],
   "source": [
    "#Code for generating data....\n",
    "datalist=[] #create an empty list\n",
    "# data list is a list of two elements, where index=0 contains data corresponding to petal \n",
    "# length and index=1 contains data corresponding to petal width\n",
    "datalist.append(list(data['PetalLength'].dropna()))\n",
    "datalist.append(list(data['PetalWidth'].dropna()))\n",
    "datalist.append(list(data['SepalLength'].dropna()))\n",
    "datalist.append(list(data['SepalWidth'].dropna()))\n",
    "\n",
    "#print (\"PetalLength=\", datalist[0])\n",
    "#print (\"PetalWidth=\", datalist[1])\n",
    "\n",
    "#This and above code are both same...\n",
    "# datalist=[0]*2#create a list of 2 elements\n",
    "# datalist[0]=(list(data['PetalLength'].dropna()))\n",
    "# datalist[1]=(list(data['PetalWidth'].dropna()))\n",
    "#data list is a list of two elements, where index=0 contains data corresponding to petal \n",
    "# length and index=1 contains data corresponding to petal width\n",
    "# print(\"PetalLength=\", datalist[0])\n",
    "# print(\"PetalWidth=\", datalist[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*In all the tasks given below use the list variable `datalist` (defined above) to answer all the questions.*\n",
    "\n",
    "####Task1\n",
    "----------------\n",
    "Write code to find the mean and variance of the both the attributes vector (petal length and petal Width) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.7744966442953043, 1.2053691275167793] [3.0755911895860546, 0.57567587045628632]\n"
     ]
    }
   ],
   "source": [
    "#Write your code here\n",
    "mean=[]\n",
    "variance=[]\n",
    "mean.append(sum(datalist[0])/len(datalist[0]))\n",
    "mean.append(sum(datalist[1])/len(datalist[1]))\n",
    "\n",
    "z1=[x-mean[0] for x in datalist[0]]\n",
    "z2=[x-mean[1] for x in datalist[1]]\n",
    "\n",
    "z1=[x**2 for x in z1]\n",
    "z2=[x**2 for x in z2]\n",
    "\n",
    "\n",
    "variance.append(sum(z1)/len(datalist[0]))\n",
    "variance.append(sum(z2)/len(datalist[1]))\n",
    "\n",
    "print(mean,variance)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Task2\n",
    "----------------\n",
    "Write code to unit normalize both (feature) vectors and compute the cosine similarity among them. Please comment does it make sense to compute the cosine similarity among the feature vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.983506230585\n"
     ]
    }
   ],
   "source": [
    "#Write your code here\n",
    "import math\n",
    "\n",
    "a_bar=[x**2 for x in datalist[0]]\n",
    "b_bar=[x**2 for x in datalist[1]]\n",
    "a_bar=sum(a_bar)\n",
    "b_bar=sum(b_bar)\n",
    "a_bar=math.sqrt(a_bar)\n",
    "b_bar=math.sqrt(b_bar)\n",
    "\n",
    "\n",
    "norm_a=[x/a_bar for x in datalist[0]]\n",
    "norm_b=[x/b_bar for x in datalist[1]]\n",
    "\n",
    "\n",
    "cosin_sim=[x*y for x,y in zip(norm_a, norm_b)]\n",
    "\n",
    "print(sum(cosin_sim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Task3: Univariate Analysis\n",
    "----------------\n",
    "Lets model the petal length as a univariate bernoulli random variable by categorizing the petal length as short(< 4.9cm) and long(>=4.9cm). Write the code for finding the probability of a short petal length flower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6577181208053692 ['Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Long', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Long', 'Short', 'Short', 'Short', 'Short', 'Long', 'Short', 'Short', 'Short', 'Short', 'Short', 'Long', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Long', 'Long', 'Long', 'Long', 'Long', 'Long', 'Short', 'Long', 'Long', 'Long', 'Long', 'Long', 'Long', 'Long', 'Long', 'Long', 'Long', 'Long', 'Long', 'Long', 'Long', 'Long', 'Long', 'Long', 'Long', 'Long', 'Short', 'Long', 'Long', 'Long', 'Long', 'Long', 'Long', 'Long', 'Long', 'Long', 'Long', 'Long', 'Short', 'Long', 'Long', 'Long', 'Long', 'Long', 'Long', 'Long', 'Long', 'Long', 'Long', 'Long']\n"
     ]
    }
   ],
   "source": [
    "#Write your code here\n",
    "bern_p_len=[\"Short\" if x<4.9 else \"Long\" for x in datalist[0]]\n",
    "p_len=bern_p_len.count(\"Short\")/len(bern_p_len)\n",
    "\n",
    "print(p_len,bern_p_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Task4: Univariate Analysis\n",
    "----------------\n",
    "Lets consider that we randomly choose 20 flower, whats the probability that 15 among them will be short petal lenght ones ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12719918570973218\n"
     ]
    }
   ],
   "source": [
    "#Write your code here\n",
    "\n",
    "f = math.factorial\n",
    "comb=f(20)/(f(15)*f(20-15))\n",
    "prob=comb*0.65**15*0.35**5\n",
    "\n",
    "print(prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Task5: Univariate Analysis\n",
    "----------------\n",
    "Lets model the petal Width as a univariate Bernoulli random variable by categorizing the petal width as short(< 1.6cm) and long(>=1.6cm). Write the code for finding the probability of a short petal width flower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6510067114093959 ['Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Long', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Long', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Long', 'Short', 'Short', 'Short', 'Short', 'Short', 'Long', 'Short', 'Long', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Short', 'Long', 'Long', 'Long', 'Long', 'Long', 'Long', 'Long', 'Long', 'Long', 'Long', 'Long', 'Long', 'Long', 'Long', 'Long', 'Long', 'Long', 'Long', 'Long', 'Short', 'Long', 'Long', 'Long', 'Long', 'Long', 'Long', 'Long', 'Long', 'Long', 'Long', 'Long', 'Long', 'Long', 'Short', 'Short', 'Long', 'Long', 'Long', 'Long', 'Long', 'Long', 'Long', 'Long', 'Long', 'Long', 'Long', 'Long', 'Long', 'Long', 'Long']\n"
     ]
    }
   ],
   "source": [
    "#Write your code here\n",
    "\n",
    "\n",
    "bern_p_wid=[\"Short\" if x<1.6 else \"Long\" for x in datalist[1]]\n",
    "p_wid=(bern_p_wid).count(\"Short\")/len(bern_p_len)\n",
    "\n",
    "print(p_wid,bern_p_wid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Task6: Univariate Analysis\n",
    "----------------\n",
    "Lets model the petal length as a univariate continuous Gaussian random variable. What is the probability of seeing a flower with the petal lenght in the range $\\in [5.6,\\; 5.7]$. Recall that a gaussian pdf is\n",
    "$$f(x) = \\frac{1}{\\sigma \\sqrt{2\\pi} } e^{ -\\frac{(x-\\mu)^2}{2\\sigma^2} }$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [],
   "source": [
    "#For calculating vector with range defined by real number\n",
    "def drange(start, stop, step):\n",
    "      \n",
    "    array=[]\n",
    "    r=start\n",
    "      \n",
    "    while(r<stop):\n",
    "        array.append(r)\n",
    "        r+=step\n",
    "        \n",
    "        \n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "breakpoint": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0128412053524 0.012854047057414494\n"
     ]
    }
   ],
   "source": [
    "#Write your code here, use summation instead of integral, \n",
    "# you are not authorized to use scipy.stats function for this and later parts...\n",
    "\n",
    "mean=[]\n",
    "variance=[]\n",
    "std_dev=[]\n",
    "summ=[]\n",
    "\n",
    "mean.append(sum(datalist[0])/len(datalist[0]))\n",
    "mean.append(sum(datalist[1])/len(datalist[1]))\n",
    "\n",
    "z1=[x-mean[0] for x in datalist[0]]\n",
    "z2=[x-mean[1] for x in datalist[1]]\n",
    "\n",
    "z1=[x**2 for x in z1]\n",
    "z2=[x**2 for x in z2]\n",
    "\n",
    "variance.append(sum(z1)/len(datalist[0]))\n",
    "variance.append(sum(z2)/len(datalist[1]))\n",
    "\n",
    "std_dev.append(math.sqrt(variance[0]))\n",
    "std_dev.append(math.sqrt(variance[1]))\n",
    "\n",
    "const=std_dev[0]*math.sqrt(2*math.pi)\n",
    "\n",
    "step=.0001\n",
    "x_value=drange(5.6,5.7,step)\n",
    "\n",
    "ex_cons=[(math.exp(-((((x-mean[0])/std_dev[0])**2)/2)))/const for x in x_value]\n",
    "\n",
    "ex_cons=[x*step for x in ex_cons]\n",
    "\n",
    "\n",
    "# FOr Checking Solution\n",
    "std=np.std(datalist[0])\n",
    "import scipy.stats as stats\n",
    "\n",
    "rn=stats.norm(mean[0],std)\n",
    "print(rn.cdf(5.7)-rn.cdf(5.6),sum(ex_cons))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Task8: Univariate Analysis\n",
    "----------------\n",
    "Lets model the petal length as a univariate continuous Gaussian random variable. What is the relative probability of seeing a flower with the petal length 5.4 to a flower with petal length 3.9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14804478060704165 0.22689957417715803\n"
     ]
    }
   ],
   "source": [
    "#Write your code here\n",
    "a1=(math.exp(-((((5.4-mean[0])/std_dev[0])**2)/2)))/const\n",
    "a2=(math.exp(-((((3.9-mean[0])/std_dev[0])**2)/2)))/const\n",
    "\n",
    "print(a1,a2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Task9: Univariate Analysis\n",
    "Write a function to build a histogarm of the given feature vector (list). Your function should receive two arguments a feature vector (a list) and number of bins and return the built histogram. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [],
   "source": [
    "def buildHistogram(feature, nbins):\n",
    "    \"\"\" Histogram the feature into number of bins \"\"\"\n",
    "    #Write your code here    \n",
    "\n",
    "    \n",
    "    \n",
    "    f=list(feature)\n",
    "    f.sort()\n",
    "\n",
    "    \n",
    "    step=max(feature)-min(feature)\n",
    "    step/=nbins\n",
    "    \n",
    "    hist=list(range(1,nbins+1))\n",
    "    range_check=[(x*step)+min(f) for x in hist]\n",
    " \n",
    "    print(\"Step is :\",step)\n",
    "    print(\"Max is :\",max(feature))\n",
    "    print(\"Min is :\",min(feature))\n",
    "    print(\"Range is :\",range_check)\n",
    "    \n",
    "    \n",
    "   \n",
    "    index=0;\n",
    "    for i in f:\n",
    "        if((i>range_check[index])):\n",
    "            if(not(index==len(hist)-1)):\n",
    "                index+=1\n",
    "        \n",
    "        hist[index]+=1\n",
    "            \n",
    "                \n",
    "           \n",
    "        \n",
    "    \n",
    "    return hist\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'datalist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-8851df4d4809>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# For checking hist funciton\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mh\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbuildHistogram\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatalist\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'datalist' is not defined"
     ]
    }
   ],
   "source": [
    "# For checking hist funciton\n",
    "\n",
    "h=buildHistogram(datalist[0],2)\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Task10: Univariate Analysis\n",
    "Write a function that returns a list containing all the four quantile of the given feature vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [],
   "source": [
    "def getQuantile(features):\n",
    "    \"\"\" Function returns the four quantile of the given feature vector in a list \"\"\"    \n",
    "    quartile=[1,2,3]\n",
    "    \n",
    "    f=list(features)\n",
    "    f.sort()\n",
    "    \n",
    "    for i in quartile:\n",
    "        index=i/4*(len(features)+1)\n",
    "        start=math.floor(index)\n",
    "        end=math.ceil(index)\n",
    "        start=f[start]\n",
    "        end=f[end]\n",
    "        a=start+end\n",
    "        if(not(start==end)):\n",
    "            quartile[i-1]=a*math.floor(index-math.floor(index))\n",
    "        else:\n",
    "            quartile[i-1]=start\n",
    "        \n",
    "    \n",
    "    return quartile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Task11: Univariate Analysis\n",
    "Find the outliers in the features petal length and width. Comment on how you have decided on the features which are outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers using Inter Quartile Range :\n",
      "#1\n",
      "Quantiles are : [1.6000000000000001, 4.4000000000000004, 5.0999999999999996]\n",
      "Range is : 5.25\n",
      "Outliers Removed : 0\n",
      "#2\n",
      "Quantiles are : [0.29999999999999999, 1.3, 1.8]\n",
      "Range is : 2.25\n",
      "Outliers Removed : 0\n",
      "Range with mean as centre : 6.13807722927\n",
      "Outliers Removed : 2\n"
     ]
    }
   ],
   "source": [
    "#Write your code here  \n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "q=getQuantile(datalist[0])\n",
    "\n",
    "print(\"Outliers using Inter Quartile Range :\")\n",
    "\n",
    "print(\"#1\")\n",
    "print(\"Quantiles are :\",q);\n",
    "\n",
    "inter_range=q[2]-q[0]\n",
    "inter_range*=1.5\n",
    "l_range=q[0]-inter_range\n",
    "h_range=q[2]+inter_range\n",
    "\n",
    "x=[x for x in datalist[0] if x>l_range]\n",
    "x=[y for y in x if y<h_range]\n",
    "\n",
    "print(\"Range is :\",inter_range)\n",
    "print(\"Outliers Removed :\",len(datalist[0])-len(x))\n",
    "\n",
    "q=getQuantile(datalist[1])\n",
    "\n",
    "print(\"#2\")\n",
    "print(\"Quantiles are :\",q);\n",
    "\n",
    "inter_range=q[2]-q[0]\n",
    "inter_range*=1.5\n",
    "l_range=q[0]-inter_range\n",
    "h_range=q[2]+inter_range\n",
    "\n",
    "x=[x for x in datalist[1] if x>l_range]\n",
    "x=[y for y in x if y<h_range]\n",
    "\n",
    "print(\"Range is :\",inter_range)\n",
    "print(\"Outliers Removed :\",len(datalist[1])-len(x))\n",
    "\n",
    "# The normal is 1.5*IQR we could customise it to our needs\n",
    "\n",
    "\n",
    "# Outliers using normal distribution\n",
    "\n",
    "range_l=[0,0]\n",
    "range_w=[0,0]\n",
    "\n",
    "range_l=[mean[0]-1.5*std_dev[0],mean[0]+2*std_dev[0]]\n",
    "range_w=[mean[0]-1.5*std_dev[1],mean[1]+2*std_dev[1]]\n",
    "\n",
    "xx=[x for x in datalist[0] if x>range_l[0] and x<range_l[1]]\n",
    "yy=[y for y in datalist[1] if y>range_w[0] and y<range_w[1]]\n",
    "\n",
    "print(\"Range with mean as centre :\",range_l[1]-range_l[0])\n",
    "print(\"Outliers Removed :\",len(datalist[0])-len(xx))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Task12: Multivariate Analysis\n",
    "Lets model the petal length and width as a bivariate Bernoulli random variable by categorizing the petal length (< 4.9cm) and petal width as short(< 1.6cm) and vice versa. Suppose that petal length is represented by random variable $x$ and petal width by random variable $y$. Now write the code for finding the probability of following cases:\n",
    "$$P(x=0, y=0)= ?$$\n",
    "$$P(x=0, y=1)= ?$$\n",
    "$$P(x=1, y=0)= ?$$\n",
    "$$P(x=1, y=1)= ?$$\n",
    "\n",
    "Here $x=0$ represent the flowers with short petal length and $x=1$ represent the flower with long petal length..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6174496644295302, 0.040268456375838924, 0.03355704697986577, 0.3087248322147651]\n"
     ]
    }
   ],
   "source": [
    "bivariate_bern_p_len=[\"Long\" if x>=4.9 else \"Short\" for x in datalist[0]]\n",
    "bivariate_bern_p_wid=[\"Long\" if x>=1.6 else \"Short\" for x in datalist[1]]\n",
    "\n",
    "\n",
    "\n",
    "probabilities=[0,0,0,0]\n",
    "\n",
    "for x,y in zip(bivariate_bern_p_len,bivariate_bern_p_wid):\n",
    "    if((x==\"Short\") and (y==\"Short\")):\n",
    "        probabilities[0]=probabilities[0]+1\n",
    "    elif((x==\"Short\") and (y==\"Long\")):    \n",
    "        probabilities[1]=probabilities[1]+1\n",
    "    elif((x==\"Long\") and (y==\"Short\")): \n",
    "        probabilities[2]=probabilities[2]+1\n",
    "    else:\n",
    "        probabilities[3]=probabilities[3]+1\n",
    "\n",
    "probs=[x/(len(bivariate_bern_p_len)) for x in probabilities]\n",
    "\n",
    "print(probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Task13: Multivariate Analysis\n",
    "What will be probability of seeing of flower with long petal length ? Find the result using marginalization principle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3422818791946309\n"
     ]
    }
   ],
   "source": [
    "long_p_len_bivariate=probs[2]+probs[3];\n",
    "\n",
    "print(long_p_len_bivariate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Task13: Multivariate Analysis\n",
    "Lets model the sepal length, sepal width, petal length and width as a multivariate Bernoulli random variable by categorizing the sepal length  as (short< 7.1cm), sepal width (short< 3.1cm), petal length (short< 4.9cm) and petal width (short< 1.6cm) and vice versa. Suppose that all four measures are represented by random variables $x_1, x_2, x_3, x_4$ respectively. Now write the code for finding the probability of the following cases:\n",
    "$$p(x_1=1, x_2=1, x_3=0, x_4=1)$$\n",
    "$$p(x_1=0, x_2=1, x_3=0, x_4=1)$$\n",
    "$$p(x_1=0, x_2=0, x_3=0, x_4=1)$$\n",
    "$$p(x_1=1, x_2=1, x_3=1, x_4=1)$$\n",
    "\n",
    "Here $x_i=0$ represent the flowers with short featuers and $x_i=1$ represent the flower with long feature.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.020134228187919462 0.020134228187919462 0.026845637583892617\n"
     ]
    }
   ],
   "source": [
    "#Write your code here\n",
    "p_l_p=[\"Long\" if x>=4.9 else \"Short\" for x in datalist[0]]\n",
    "p_w_p=[\"Long\" if x>=1.6 else \"Short\" for x in datalist[1]]\n",
    "s_l_p=[\"Long\" if x>=7.1 else \"Short\" for x in datalist[2]]\n",
    "s_w_p=[\"Long\" if x>=3.1 else \"Short\" for x in datalist[3]]\n",
    "\n",
    "\n",
    "p1=0\n",
    "p2=0\n",
    "p3=0\n",
    "p4=0\n",
    "\n",
    "for a,b,c,d in zip(p_l_p,p_w_p,s_l_p,s_w_p):\n",
    "    if((c==\"Long\")and(d==\"Long\")and(a==\"Short\")and(b==\"Long\")):\n",
    "        p1+=1\n",
    "    elif((c==\"Short\")and(d==\"Long\")and(a==\"Short\")and(b==\"Long\")):\n",
    "        p2+=1\n",
    "    elif((c==\"Short\")and(d==\"Short\")and(a==\"Short\")and(b==\"Long\")):\n",
    "        p3+=1\n",
    "    elif((c==\"Long\")and(d==\"Long\")and(a==\"Long\")and(b==\"Long\")):\n",
    "        p4+=1\n",
    "        \n",
    "p1/=len(p_l_p)\n",
    "p2/=len(p_l_p)\n",
    "p3/=len(p_l_p)\n",
    "p4/=len(p_l_p)\n",
    "\n",
    "print(p1,p2,p3,p4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Task14: Multivariate Analysis\n",
    "Find the following probabilities using marginalization principle:\n",
    "$$p(x_1=1, x_2=1,  x_4=1)$$\n",
    "$$p(x_1=0, x_4=1)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.026845637583892617 0.2684563758389262\n"
     ]
    }
   ],
   "source": [
    "#Write your code here\n",
    "\n",
    "p11=0\n",
    "p22=0\n",
    "\n",
    "for a,b,c,d in zip(p_l_p,p_w_p,s_l_p,s_w_p):\n",
    "    if((c==\"Long\")and(d==\"Long\")and(b==\"Long\")):\n",
    "         p11+=1\n",
    "    elif((c==\"Short\")and(b==\"Long\")):    \n",
    "         p22+=1\n",
    "\n",
    "p11/=len(p_l_p)\n",
    "p22/=len(p_l_p)\n",
    "\n",
    "print(p11,p22)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
